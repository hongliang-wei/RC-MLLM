## RC-MLLM
Region-Level Context-Aware Multimodal Understanding  
##Demos:[[Celebrity Recognition and VQA](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)]  
##Models[[Models](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)]  
📑 [Arxiv](https://arxiv.org/abs/your-paper-id) |
🤗 型号：[RC-Qwen2VL-2b](https://huggingface.co/weihongliang/RC-Qwen2VL-2b/blob/main/README.md) [RC-Qwen2VL-7b](https://huggingface.co/weihongliang/RC-Qwen2VL-7b/blob/main/README.md)|
📁 [数据集](https://huggingface.co/your-model-name) |
[Github](https://github.com/hongliang-wei/RC-MLLM) |
##🚀Demos: [Personalized Multimodal Understanding](https://your-project-url.com) [Celebrity Recognition and VQA](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)
