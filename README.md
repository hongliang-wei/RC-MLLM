## RC-MLLM
Region-Level Context-Aware Multimodal Understanding  
##Demos:[[Celebrity Recognition and VQA](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)]  
##Models[[Models](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)]  
ğŸ“‘ [Arxiv](https://arxiv.org/abs/your-paper-id) |
ğŸ¤— å‹å·ï¼š[RC-Qwen2VL-2b](https://huggingface.co/weihongliang/RC-Qwen2VL-2b/blob/main/README.md) [RC-Qwen2VL-7b](https://huggingface.co/weihongliang/RC-Qwen2VL-7b/blob/main/README.md)|
ğŸ“ [æ•°æ®é›†](https://huggingface.co/your-model-name) |
[Github](https://github.com/hongliang-wei/RC-MLLM) |
##ğŸš€Demos: [Personalized Multimodal Understanding](https://your-project-url.com) [Celebrity Recognition and VQA](https://github.com/hongliang-wei/RC-MLLM/edit/main/README.md)
